{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "from getdist import loadMCSamples, plots, mcsamples\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from copy import deepcopy\n",
    "#from classy import Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "cool = matplotlib.cm.get_cmap('cool')\n",
    "import matplotlib\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "matplotlib.rcParams['font.size'] = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_systematics(samples1, samples2, cosmo, truth1, truth2):\n",
    "    shift1 = get_shifts(samples1, cosmo, truth1)\n",
    "    shift2 = get_shifts(samples2, cosmo, truth2)\n",
    "    sigma1 = get_sigmas(samples1, cosmo)\n",
    "    sigma2 = get_sigmas(samples2, cosmo)\n",
    "    systematics = []\n",
    "    for i, (name, e1, e2, s1, s2) in enumerate(zip(cosmo, shift1, shift2, sigma1, sigma2)):\n",
    "        err = s1*s2/np.sqrt(s1**2+s2**2)\n",
    "        shift = abs(e1*s2**2 + e2*s1**2)/(s1**2+s2**2)\n",
    "        sys = shift-err\n",
    "        if sys < 0: \n",
    "            sys = 0.\n",
    "        systematics.append((name, np.round(err, 4), np.round(sys, 4)))\n",
    "        # systematics.append([np.round(err, 4), np.round(sys, 4)])\n",
    "    return systematics\n",
    "\n",
    "def get_systematics(samples, cosmo, truth, data_errors=None):\n",
    "    systematics = []\n",
    "    for i, name in enumerate(cosmo):\n",
    "        stats = samples.getMargeStats().parWithName(name)\n",
    "        lower = stats.limits[0].lower\n",
    "        upper = stats.limits[0].upper\n",
    "        err = stats.err\n",
    "        if truth[name] - upper > 0: syst = upper - truth[name]\n",
    "        elif lower - truth[name] > 0: syst = lower - truth[name]\n",
    "        else: syst = 0.\n",
    "        if data_errors is None: systematics.append( syst / err )\n",
    "        else: systematics.append( syst / data_errors[name] )\n",
    "    return np.array(systematics)\n",
    "\n",
    "def get_phase_space(samples, samples_ref, cosmo):\n",
    "    shifts = []\n",
    "    allstats = samples.getMargeStats()\n",
    "    allstats_ref = samples_ref.getMargeStats()\n",
    "    for i, name in enumerate(cosmo):\n",
    "        stats = allstats.parWithName(name)\n",
    "        mean = stats.mean\n",
    "        err = stats.err\n",
    "        #lower = stats.limits[0].lower\n",
    "        #upper = stats.limits[0].upper\n",
    "        #if mean > truth[name]: err = upper-mean\n",
    "        #else: err = mean-lower\n",
    "        shift = (mean-allstats_ref.parWithName(name).mean) / err\n",
    "        shifts.append(shift)\n",
    "    return np.array( shifts )\n",
    "\n",
    "def get_relative_shifts(samples1, samples2, cosmo):\n",
    "    shifts = []\n",
    "    allstats1 = samples1.getMargeStats()\n",
    "    allstats2 = samples2.getMargeStats()\n",
    "    for i, name in enumerate(cosmo):\n",
    "        stats1 = allstats1.parWithName(name)\n",
    "        stats2 = allstats2.parWithName(name)\n",
    "        shift = 2. * (stats1.mean-stats2.mean) / (stats1.err + stats2.err)\n",
    "        shifts.append(shift)\n",
    "    return np.array( shifts )\n",
    "\n",
    "def get_sigma_deviation(samples1, samples2, cosmo):\n",
    "    shifts = []\n",
    "    allstats1 = samples1.getMargeStats()\n",
    "    allstats2 = samples2.getMargeStats()\n",
    "    for i, name in enumerate(cosmo):\n",
    "        stats1 = allstats1.parWithName(name)\n",
    "        stats2 = allstats2.parWithName(name)\n",
    "        shift = (stats1.mean-stats2.mean) / np.sqrt(stats1.err**2 + stats2.err**2)\n",
    "        #print(stats1.mean-stats2.mean, np.sqrt(stats1.err**2 + stats2.err**2))\n",
    "        shifts.append(shift)\n",
    "    return np.array( shifts )\n",
    "\n",
    "def get_relative_tension(samples1, samples2, cosmo):\n",
    "    shifts = []\n",
    "    allstats1 = samples1.getMargeStats()\n",
    "    allstats2 = samples2.getMargeStats()\n",
    "    for i, name in enumerate(cosmo):\n",
    "        stats1 = allstats1.parWithName(name)\n",
    "        stats2 = allstats2.parWithName(name)\n",
    "        shift = (stats1.mean-stats2.mean) / np.sqrt(stats1.err**2 + stats2.err**2)\n",
    "        shifts.append(shift)\n",
    "    return np.array( shifts )\n",
    "\n",
    "def get_relative_shifts_from_truth(samples, cosmo, truth, samples_ref=None):\n",
    "    shifts = []\n",
    "    allstats = samples.getMargeStats()\n",
    "    if samples_ref is not None: allstats_ref = samples.getMargeStats()\n",
    "    for i, name in enumerate(cosmo):\n",
    "        stats = allstats.parWithName(name)\n",
    "        mean = stats.mean\n",
    "        # err = stats.err\n",
    "        if samples_ref is not None: stats = allstats_ref.parWithName(name)\n",
    "        lower = stats.limits[0].lower\n",
    "        upper = stats.limits[0].upper\n",
    "        if mean > truth[name]: err = upper-mean\n",
    "        else: err = mean-lower\n",
    "        shift = (mean-truth[name]) / err\n",
    "        shifts.append(shift)\n",
    "    return np.array( shifts )\n",
    "\n",
    "def get_relative_shifts_from_truth_2(samples, cosmo, truth):\n",
    "    shifts = []\n",
    "    for i, name in enumerate(cosmo):\n",
    "        ix = samples.getParamNames().list().index(name)\n",
    "        mean = samples.mean(ix)\n",
    "        lower = samples.confidence(ix, limfrac=0.31, upper=False)\n",
    "        upper = samples.confidence(ix, limfrac=0.31, upper=True)\n",
    "        err = upper - lower\n",
    "        shift = (mean-truth[name]) / err\n",
    "        shifts.append(shift)\n",
    "    return np.array( shifts )\n",
    "\n",
    "def get_shifts_from_truth_2(samples, cosmo, truth):\n",
    "    shifts = []\n",
    "    for i, name in enumerate(cosmo):\n",
    "        ix = samples.getParamNames().list().index(name)\n",
    "        mean = samples.mean(ix)\n",
    "        lower = samples.confidence(ix, limfrac=0.31, upper=False)\n",
    "        upper = samples.confidence(ix, limfrac=0.31, upper=True)\n",
    "        err = upper - lower\n",
    "        shift = (mean-truth[name])\n",
    "        shifts.append(shift)\n",
    "    return np.array( shifts )\n",
    "\n",
    "def get_errors_2(samples, cosmo, truth):\n",
    "    shifts = []\n",
    "    for i, name in enumerate(cosmo):\n",
    "        ix = samples.getParamNames().list().index(name)\n",
    "        mean = samples.mean(ix)\n",
    "        lower = samples.confidence(ix, limfrac=0.31, upper=False)\n",
    "        upper = samples.confidence(ix, limfrac=0.31, upper=True)\n",
    "        err = upper - lower\n",
    "        shifts.append(err)\n",
    "    return np.array(shifts)\n",
    "\n",
    "def get_error_ratio(samples, samples_ref, cosmo):\n",
    "    error_ratio = []\n",
    "    for i, name in enumerate(cosmo):\n",
    "        sigma = samples.getMargeStats().parWithName(name).err\n",
    "        sigma_ref = samples_ref.getMargeStats().parWithName(name).err\n",
    "        error_ratio.append( sigma / sigma_ref )\n",
    "    return np.array(error_ratio)\n",
    "\n",
    "def get_errors(samples, cosmo):\n",
    "    errors = {}\n",
    "    for i, name in enumerate(cosmo):\n",
    "        errors[name] = samples.getMargeStats().parWithName(name).err\n",
    "    return errors\n",
    "\n",
    "def get_means(samples, cosmo):\n",
    "    means = {}\n",
    "    for i, name in enumerate(cosmo):\n",
    "        means[name] = samples.getMargeStats().parWithName(name).mean\n",
    "    return means\n",
    "\n",
    "def get_Omega_m(samples, nu=False):\n",
    "    p=samples.getParams()\n",
    "    if nu: samples.addDerived((p.omega_b*1e-2+p.omega_cdm)/p.h**2 + p.M_tot_NH/93.14/p.h**2, name='Omega_m', label=r'\\Omega_m')\n",
    "    else: samples.addDerived((p.omega_b*1e-2+p.omega_cdm)/p.h**2, name='Omega_m', label=r'\\Omega_m')\n",
    "\n",
    "        \n",
    "def resample_nu(samples):\n",
    "    p=samples.getParams()\n",
    "    weights = - np.log( np.heaviside( 0.09 - p.M_tot_NH, 0 ) + 1e-16 )\n",
    "    samples.reweightAddingLogLikes(weights)\n",
    "\n",
    "def resampleBBN(samples, truth=2.14394):\n",
    "    p=samples.getParams()\n",
    "    weights = 0.5 * ((p.omega_b-truth)/0.035)**2 - 0.5 * ((p.omega_b-truth)/0.05)**2 # chi2 = - log(L) = - Log(exp(-p^2/(2s^2))) = (p/s)^2 /2 \n",
    "    samples.reweightAddingLogLikes(weights)\n",
    "    \n",
    "def resample_ns(samples, truth=.96):\n",
    "    p=samples.getParams()\n",
    "    weights = 0.5 * ((p.n_s-truth)/0.02)**2 \n",
    "    samples.reweightAddingLogLikes(weights)\n",
    "    \n",
    "def prior(bs, prior_mean, prior_sigma, prior_type='gauss'):\n",
    "        if 'gauss' in prior_type: \n",
    "            prior = - 0.5 * (bs - prior_mean)**2 / prior_sigma**2\n",
    "        elif 'lognormal'in prior_type:\n",
    "            prior = - 0.5 * (np.log(bs) - prior_mean)**2 / prior_sigma**2 #- np.log(bs)     \n",
    "        return prior\n",
    "\n",
    "def set_prior_nongauss(samples, log_b1_mean=0.8, log_b1_sigma=0.8944, b1type='lognormal', prior_sigma=2., invprior=False): # Prior for non-Gaussian parameter: Log-normal prior on b1 and Gaussian prior on c2\n",
    "    p = samples.getParams()\n",
    "    b1, c2 = p.b1_hN, p.c2_hN\n",
    "    prior1 = 0. * prior(b1, log_b1_mean, log_b1_sigma, prior_type='lognormal')\n",
    "    prior2 = prior(c2, 0., prior_sigma)\n",
    "    try:\n",
    "        c4 = p.c4_hN\n",
    "        prior4 = prior(c4, 0., prior_sigma)\n",
    "    except:\n",
    "        prior4 = 0.\n",
    "    weights = - ( prior1 + prior2 + prior4 )\n",
    "#     b1, c2, c4 = p.b1_hS, p.c2_hS, p.c4_hS\n",
    "#     prior1 = prior(b1, log_b1_mean, log_b1_sigma, prior_type='lognormal')\n",
    "#     prior2 = prior(c2, 0., prior_sigma)\n",
    "#     prior4 = prior(c4, 0., prior_sigma)\n",
    "#     weights += - ( prior1 + prior2 + prior4 )\n",
    "    if invprior: weights = -weights\n",
    "    samples.reweightAddingLogLikes(weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighting_A_s(samples):\n",
    "    p=samples.getParams()\n",
    "    try:\n",
    "        weights = 0.\n",
    "#         for c2 in [p.c2_hN, p.c2_hS, p.c2_lN, p.c2_lS]:\n",
    "#             weights += 0. * np.log(c2 + 4)\n",
    "        for c4 in [p.c4_hN, p.c4_hS, p.c4_lN, p.c4_lS]:\n",
    "            weights += 2. * np.log(c4 + 4.01)\n",
    "    except: \n",
    "        weights = 0.\n",
    "#         for c2 in [p.c2_hN]: #, p.c2_hS, p.c2_lN, p.c2_lS]:\n",
    "#             weights += 0. * np.log(c2 + 4)\n",
    "        for c4 in [p.c4_hN]: #, p.c2_hS, p.c2_lN, p.c2_lS]:\n",
    "            weights -= 2. * np.log(c4 + 4.01)\n",
    "    samples.reweightAddingLogLikes(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relative_posteriors(samples, truth, doBBN=False):\n",
    "    p=samples.getParams()\n",
    "    # if doBBN: resampleBBN(samples, truth=truth['omega_b']*100.)\n",
    "    samples.addDerived(p.h/truth['h']-1, name='rh', label=r'\\Delta h/h')\n",
    "    try: samples.addDerived(np.log(1e10*p.A_s)/truth['ln10^{10}A_s']-1, name='rlnA_s', label=r'\\Delta \\ln 10^{10}A_s/\\ln10^{10}A_s')\n",
    "    except: samples.addDerived(p.lnA_s/truth['ln10^{10}A_s']-1, name='rlnA_s', label=r'\\Delta ln10^{10}A_s/ln10^{10}A_s')\n",
    "    # samples.addDerived(np.exp(p.lnA_s)/ np.exp(truth['ln10^{10}A_s'])-1, name='rA_s', label=r'\\Delta A_s/A_s')\n",
    "    samples.addDerived(p.omega_cdm/truth['omega_cdm']-1, name='romega_cdm', label=r'\\Delta \\omega_{cdm}/\\omega_{cdm}')\n",
    "    # samples.addDerived(p.n_s/truth['n_s']-1, name='rn_s', label=r'\\Delta n_s/n_s')\n",
    "    samples.addDerived(p.Omega_m/truth['Omega_m']-1, name='rOmega_m', label=r'\\Delta \\Omega_m/\\Omega_m')\n",
    "    samples.addDerived(p.sigma8/truth['sigma8']-1, name='rsigma8', label=r'\\Delta \\sigma_8/\\sigma_8')\n",
    "    # samples.addDerived((p.omega_b*1e-2+p.omega_cdm)/p.h**2/truth['Omega_m']-1, name='rOmega_m', label=r'\\Delta \\Omega_m/\\Omega_m')\n",
    "\n",
    "def weighting_A_s(samples, ps=False):\n",
    "    p=samples.getParams()\n",
    "    weights = 0.\n",
    "    samples.reweightAddingLogLikes(weights)\n",
    "    \n",
    "def load_chain(chainname, truth=None, basedir='./', doBBN=False, add_Omega_m=False, sample_A_s_ps=False, \n",
    "               sample_A_s=False, fix_ns=False, process_ng=False, cutnu=False):\n",
    "    try: \n",
    "        chains = os.path.join(basedir, chainname)\n",
    "        samples = loadMCSamples(chains, settings={'ignore_rows':0});\n",
    "    except: \n",
    "        chains = os.path.join(basedir, chainname, chainname)\n",
    "        samples = loadMCSamples(chains, settings={'ignore_rows':0});\n",
    "    if cutnu: resample_nu(samples)\n",
    "    if doBBN: resampleBBN(samples)\n",
    "    if truth is not None: get_relative_posteriors(samples, truth)\n",
    "    if add_Omega_m: get_Omega_m(samples)\n",
    "    if sample_A_s: weighting_A_s(samples)\n",
    "    if sample_A_s_ps:\n",
    "        weighting_A_s(samples, ps=True)\n",
    "    if fix_ns: resample_ns(samples)\n",
    "    if process_ng: set_prior_nongauss(samples)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bestfit_from_montepython(pathdir):\n",
    "    values = np.loadtxt(open(os.path.join(pathdir, 'bf_nils.minimized'), 'r')) # the values\n",
    "    l = [] # the keys\n",
    "    with open(os.path.join(pathdir, 'bf_nils.minimized'), 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.replace(' ', '')\n",
    "            line = line.replace('#', '')\n",
    "            line = line.replace('\\n', '')\n",
    "            l.append(line.split(','))\n",
    "\n",
    "    bestfit = {}\n",
    "    for (key, value) in list(zip(l[0], values)):\n",
    "        bestfit[key] = value\n",
    "    return bestfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_truth = {'omega_b': 0.02303, 'omega_cdm': 0.11711, 'h': 0.7, \n",
    "           'ln10^{10}A_s': 3.06652, 'n_s': 0.96, 'Omega_m': 0.286}\n",
    "p_truth = {'omega_b': 0.02214, 'omega_cdm': 0.118911, 'h': 0.6777, \n",
    "               'ln10^{10}A_s': 3.06652, 'n_s': 0.9611, 'Omega_m': 0.307115}\n",
    "\n",
    "# p_truth.update({'sigma8': 0.8288}) # BOSS MDmock\n",
    "p_truth.update({'sigma8': 0.8225})# eBOSS EZmock # https://arxiv.org/pdf/2007.08999v1.pdf\n",
    "p_truth.update({'S8': 0.8225*np.sqrt(0.307115/0.3)})\n",
    "\n",
    "pt_truth = {'omega_b': 0.0214394, 'omega_cdm': 0.11503, 'h': 0.654083, 'ln10^{10}A_s': 3.05147, 'n_s': 0.965,}\n",
    "pt_truth.update({'Omega_m': 0.318986, 'sigma8': 0.8049})\n",
    "\n",
    "cola_truth = {'omega_b': 0.02210, 'omega_cdm': 0.1166, 'h': 0.68, 'ln10^{10}A_s': 3.069, 'n_s': 0.96}\n",
    "cola_truth.update({'Omega_m': 0.300, 'sigma8': 0.82})\n",
    "\n",
    "planck_truth = {'omega_b': 2.2237, 'omega_cdm': 0.120, 'h': 0.6736, \n",
    "               'ln10^{10}A_s': 3.044, 'n_s': 0.965, 'Omega_m': 0.3153} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_multi(runs, labels):\n",
    "    chains = []\n",
    "    for run in runs :\n",
    "        chains.append(load_chain(run, truth=None, basedir=basedir))\n",
    "    return chains, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matplotlib.style.use('default')\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "\n",
    "rec = plots.getSinglePlotter(ratio=1,width_inch=8)\n",
    "rec.settings.axes_fontsize = 24\n",
    "rec.settings.lab_fontsize = 24\n",
    "rec.settings.legend_fontsize = 18\n",
    "\n",
    "\n",
    "tri = plots.getSubplotPlotter(width_inch=8)\n",
    "tri.settings.axes_fontsize = 24\n",
    "tri.settings.lab_fontsize = 24\n",
    "tri.settings.legend_fontsize = 18\n",
    "tri.settings.scaling = True\n",
    "#tri.settings.alpha_filled_add=0.6\n",
    "\n",
    "oneD = plots.get_subplot_plotter(width_inch=15)\n",
    "oneD.settings.axes_fontsize = 24\n",
    "oneD.settings.lab_fontsize = 24\n",
    "oneD.settings.legend_fontsize = 18\n",
    "oneD.settings.scaling = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEST-FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h : $0.6816^{+0.0052}_{-0.0052}$\n",
      "om_b : $0.0224^{+0.0002}_{-0.0002}$\n",
      "om_cdm : $0.1184^{+0.0013}_{-0.0013}$\n",
      "ns : $0.9710^{+0.0062}_{-0.0062}$\n",
      "log_A : $3.0250^{+0.0183}_{-0.0183}$\n",
      "t_reio : $0.0474^{+0.0085}_{-0.0085}$\n",
      "Omega_m : $0.3032^{+0.0071}_{-0.0071}$\n",
      "sigma8 : $0.8115^{+0.0093}_{-0.0093}$\n",
      "h : $0.6816^{+0.0052}_{-0.0051}$\n",
      "om_b : $0.0224^{+0.0002}_{-0.0002}$\n",
      "om_cdm : $0.1184^{+0.0013}_{-0.0013}$\n",
      "ns : $0.9710^{+0.0062}_{-0.0062}$\n",
      "log_A : $3.0250^{+0.0189}_{-0.0161}$\n",
      "t_reio : $0.0474^{+0.0088}_{-0.0072}$\n",
      "Omega_m : $0.3032^{+0.0071}_{-0.0071}$\n",
      "sigma8 : $0.8115^{+0.0092}_{-0.0094}$\n",
      "S8: 0.8179585092872195\n"
     ]
    }
   ],
   "source": [
    "chainname = \"LCDM_SPT_PlTT650_BAO_Pan+\"\n",
    "chains = os.path.join('chains/LCDM/LCDM_SPT_PlTT650_BAO_Pan+', chainname)\n",
    "planck = loadMCSamples(chains, settings={'ignore_rows':0.0});\n",
    "p=planck.getParams()\n",
    "planck.addDerived(p.H0/100., name='h', label=r'h')\n",
    "planck.addDerived(p.omega_b/100., name='om_b', label=r'\\omega_b')\n",
    "planck.addDerived(p.omega_cdm, name='om_cdm', label=r'\\omega_{cdm}')\n",
    "planck.addDerived(p.logA, name='log_A', label=r'\\log(10^{10} A_s)')\n",
    "planck.addDerived(p.n_s, name='ns', label=r'n_s')\n",
    "planck.addDerived(p.tau_reio, name='t_reio', label=r'\\tau_{reio}')\n",
    "\n",
    "\n",
    "\n",
    "cosmo = ['h','om_b','om_cdm','ns','log_A','t_reio','Omega_m','sigma8']\n",
    "planck_mean = get_means(planck, cosmo)\n",
    "planck_error = get_errors(planck,cosmo)\n",
    "\n",
    "#with np.printoptions(precision=4):\n",
    "#    for i in cosmo:\n",
    "#        print(i,':', r'$%.4f^{+%.4f}_{-%.4f}$' % (planck_mean[i], planck_error[i], planck_error[i]))\n",
    "\n",
    "for i in cosmo:\n",
    "    stats = planck.getMargeStats().parWithName(i)\n",
    "    mean, cl68, cl95 = stats.mean, stats.limits[0], stats.limits[1]\n",
    "    err = np.array([mean-cl68.lower, cl68.upper-mean]).reshape(2,-1)\n",
    "    print(i,':', r'$%.4f^{+%.4f}_{-%.4f}$' % (mean, err[1], err[0]))\n",
    "\n",
    "\n",
    "        \n",
    "planck_bestfit = get_bestfit_from_montepython(\"chains/LCDM/LCDM_SPT_PlTT650_BAO_Pan+\")\n",
    "planck_bestfit['S8'] = planck_bestfit['sigma8']*np.sqrt(planck_bestfit['Omega_m']/0.3)\n",
    "\n",
    "print('S8:',planck_bestfit['S8'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
